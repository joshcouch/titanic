{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old feature engineering was for RF model. Trying again with XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshc\\anaconda3\\envs\\pytorch\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Paths\n",
    "train_csv_path = \"C:/Users/joshc/OneDrive/Documents/01 Trying too hard/Machine Learning and AI/Kaggle/titanic/Datasets/train.csv\"\n",
    "final_test_csv_path = \"C:/Users/joshc/OneDrive/Documents/01 Trying too hard/Machine Learning and AI/Kaggle/titanic/Datasets/test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005007</td>\n",
       "      <td>-0.035144</td>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.012658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.005007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.035144</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.096067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId  Survived    Pclass       Age     SibSp     Parch  \\\n",
       "PassengerId     1.000000 -0.005007 -0.035144  0.036847 -0.057527 -0.001652   \n",
       "Survived       -0.005007  1.000000 -0.338481 -0.077221 -0.035322  0.081629   \n",
       "Pclass         -0.035144 -0.338481  1.000000 -0.369226  0.083081  0.018443   \n",
       "Age             0.036847 -0.077221 -0.369226  1.000000 -0.308247 -0.189119   \n",
       "SibSp          -0.057527 -0.035322  0.083081 -0.308247  1.000000  0.414838   \n",
       "Parch          -0.001652  0.081629  0.018443 -0.189119  0.414838  1.000000   \n",
       "Fare            0.012658  0.257307 -0.549500  0.096067  0.159651  0.216225   \n",
       "\n",
       "                 Fare  \n",
       "PassengerId  0.012658  \n",
       "Survived     0.257307  \n",
       "Pclass      -0.549500  \n",
       "Age          0.096067  \n",
       "SibSp        0.159651  \n",
       "Parch        0.216225  \n",
       "Fare         1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df = pd.read_csv(train_csv_path)\n",
    "base_df.info()\n",
    "base_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.hist(base_df[\"Age\"])\n",
    "ax.tick_params(axis=\"both\", color=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cabin exploration\n",
    "def get_deck(cabin):\n",
    "    if cabin == cabin:\n",
    "        return cabin[:1]\n",
    "    else:\n",
    "        return \"no_deck\"\n",
    "\n",
    "deck = pd.DataFrame(base_df[\"Cabin\"].apply(get_deck))\n",
    "deck.rename(columns={\"Cabin\": \"Deck\"}, inplace=True)\n",
    "train_df = pd.concat([base_df, deck], axis=1)[[\"Survived\", \"Deck\"]]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.bar(train_df.groupby(\"Deck\").mean().index, train_df.groupby(\"Deck\").mean()[\"Survived\"])\n",
    "ax.tick_params(axis=\"x\", color=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(in_df):\n",
    "    out_df = in_df.copy()\n",
    "    \n",
    "    # Fill NA for age with mode\n",
    "    age_mode = out_df[\"Age\"].mode()[0]\n",
    "    out_df[\"Age\"] = out_df[\"Age\"].fillna(age_mode)\n",
    "    out_df[\"child\"] = (out_df[\"Age\"] <= 15).astype(int)\n",
    "\n",
    "    # Get dummies for sex\n",
    "    gender_dummies = pd.get_dummies(out_df[\"Sex\"]).astype(int)\n",
    "    out_df = pd.concat([out_df, gender_dummies], axis=1)\n",
    "\n",
    "    # Get dummies for embarkation port\n",
    "    port_dummies = pd.get_dummies(out_df[\"Embarked\"]).astype(int)\n",
    "    out_df = pd.concat([out_df, port_dummies], axis=1)\n",
    "\n",
    "    # Get title from name, then get dummies\n",
    "    def get_title(name):\n",
    "        title = re.sub(\", \", \"\", re.search(\", \\w+\", name).group(0))\n",
    "        if title not in [\"Mr\", \"Miss\", \"Mrs\", \"Master\"]:\n",
    "            title = \"other\"\n",
    "        return title\n",
    "\n",
    "    out_df[\"title\"] = out_df[\"Name\"].apply(get_title)\n",
    "    title_dummies = pd.get_dummies(out_df[\"title\"]).astype(int)\n",
    "    out_df = pd.concat([out_df, title_dummies], axis=1)\n",
    "\n",
    "    # Get deck from Cabin, then get dummies\n",
    "    def get_deck(cabin):\n",
    "        if cabin == cabin:\n",
    "            return cabin[:1]\n",
    "        else:\n",
    "            return \"no_deck\"\n",
    "        \n",
    "    deck = pd.DataFrame(in_df[\"Cabin\"].apply(get_deck))\n",
    "    deck_dummies = pd.get_dummies(deck).astype(int)\n",
    "    out_df = pd.concat([out_df, deck_dummies], axis=1)\n",
    "\n",
    "    # Drop non-numerical\n",
    "    out_df = out_df.select_dtypes(exclude=\"object\")\n",
    "    columns_to_drop = [\"PassengerId\", \"SibSp\", \"Parch\", \"Q\", \"male\", \"Cabin_T\", \n",
    "                       \"Cabin_G\", \"other\", \"Cabin_A\", \"Cabin_F\", \"Age\", \"S\", \n",
    "                       \"Master\", \"Cabin_C\", \"Cabin_E\", \"Cabin_B\", \"Cabin_D\", \"C\"]\n",
    "    columns_to_drop = [col for col in columns_to_drop if col in out_df.columns]\n",
    "    out_df.drop(columns=columns_to_drop, inplace=True)\n",
    "    \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr              -0.549199\n",
       "Pclass          -0.338481\n",
       "Cabin_no_deck   -0.316912\n",
       "child            0.136107\n",
       "Fare             0.257307\n",
       "Miss             0.327093\n",
       "Mrs              0.339040\n",
       "female           0.543351\n",
       "Survived         1.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = prep_data(base_df)\n",
    "train_df.corr()[\"Survived\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns=\"Survived\")\n",
    "y = train_df[\"Survived\"]\n",
    "\n",
    "# Feature scaling\n",
    "columns = X.columns\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "X_scaled = std_scaler.fit_transform(X.to_numpy())\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.831 (0.037)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate default XGBClassifier()\n",
    "\n",
    "# Define model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Fit model\n",
    "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1234)\n",
    "n_scores = cross_val_score(model, X_scaled, y, scoring='accuracy', cv=rskf, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished model: max_depth = 1, n_estimators = 10 --> mean_score = 0.787\n",
      "Finished model: max_depth = 1, n_estimators = 50 --> mean_score = 0.790\n",
      "Finished model: max_depth = 1, n_estimators = 100 --> mean_score = 0.795\n",
      "Finished model: max_depth = 1, n_estimators = 500 --> mean_score = 0.802\n",
      "Finished model: max_depth = 2, n_estimators = 10 --> mean_score = 0.802\n",
      "Finished model: max_depth = 2, n_estimators = 50 --> mean_score = 0.820\n",
      "Finished model: max_depth = 2, n_estimators = 100 --> mean_score = 0.823\n",
      "Finished model: max_depth = 2, n_estimators = 500 --> mean_score = 0.825\n",
      "Finished model: max_depth = 3, n_estimators = 10 --> mean_score = 0.817\n",
      "Finished model: max_depth = 3, n_estimators = 50 --> mean_score = 0.829\n",
      "Finished model: max_depth = 3, n_estimators = 100 --> mean_score = 0.823\n",
      "Finished model: max_depth = 3, n_estimators = 500 --> mean_score = 0.817\n",
      "Finished model: max_depth = 4, n_estimators = 10 --> mean_score = 0.827\n",
      "Finished model: max_depth = 4, n_estimators = 50 --> mean_score = 0.828\n",
      "Finished model: max_depth = 4, n_estimators = 100 --> mean_score = 0.830\n",
      "Finished model: max_depth = 4, n_estimators = 500 --> mean_score = 0.815\n",
      "Finished model: max_depth = 5, n_estimators = 10 --> mean_score = 0.831\n",
      "Finished model: max_depth = 5, n_estimators = 50 --> mean_score = 0.826\n",
      "Finished model: max_depth = 5, n_estimators = 100 --> mean_score = 0.824\n",
      "Finished model: max_depth = 5, n_estimators = 500 --> mean_score = 0.814\n",
      "Finished model: max_depth = 6, n_estimators = 10 --> mean_score = 0.829\n",
      "Finished model: max_depth = 6, n_estimators = 50 --> mean_score = 0.829\n",
      "Finished model: max_depth = 6, n_estimators = 100 --> mean_score = 0.825\n",
      "Finished model: max_depth = 6, n_estimators = 500 --> mean_score = 0.818\n",
      "Finished model: max_depth = 7, n_estimators = 10 --> mean_score = 0.829\n",
      "Finished model: max_depth = 7, n_estimators = 50 --> mean_score = 0.829\n",
      "Finished model: max_depth = 7, n_estimators = 100 --> mean_score = 0.826\n",
      "Finished model: max_depth = 7, n_estimators = 500 --> mean_score = 0.814\n",
      "Finished model: max_depth = 8, n_estimators = 10 --> mean_score = 0.829\n",
      "Finished model: max_depth = 8, n_estimators = 50 --> mean_score = 0.833\n",
      "Finished model: max_depth = 8, n_estimators = 100 --> mean_score = 0.825\n",
      "Finished model: max_depth = 8, n_estimators = 500 --> mean_score = 0.815\n",
      "Finished model: max_depth = 9, n_estimators = 10 --> mean_score = 0.829\n",
      "Finished model: max_depth = 9, n_estimators = 50 --> mean_score = 0.831\n",
      "Finished model: max_depth = 9, n_estimators = 100 --> mean_score = 0.826\n",
      "Finished model: max_depth = 9, n_estimators = 500 --> mean_score = 0.815\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.833117</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.831257</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.831240</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.829746</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.829392</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.828997</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.828656</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.828656</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.828635</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.828618</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.828618</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.827507</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.826792</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.826384</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.826009</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.825647</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.825264</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.824890</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.824519</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.823762</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.823387</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.823375</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.819671</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.817794</td>\n",
       "      <td>6</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.817428</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.817420</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.815181</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.815181</td>\n",
       "      <td>9</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.815169</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.814057</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.813670</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.802459</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.802081</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.794603</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.790487</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.786750</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_score  max_depth  n_estimators\n",
       "29    0.833117          8            50\n",
       "16    0.831257          5            10\n",
       "33    0.831240          9            50\n",
       "14    0.829746          4           100\n",
       "20    0.829392          6            10\n",
       "25    0.828997          7            50\n",
       "32    0.828656          9            10\n",
       "24    0.828656          7            10\n",
       "28    0.828635          8            10\n",
       "9     0.828618          3            50\n",
       "21    0.828618          6            50\n",
       "13    0.827507          4            50\n",
       "12    0.826792          4            10\n",
       "17    0.826384          5            50\n",
       "26    0.826009          7           100\n",
       "34    0.825647          9           100\n",
       "30    0.825264          8           100\n",
       "22    0.824890          6           100\n",
       "7     0.824519          2           500\n",
       "18    0.823762          5           100\n",
       "10    0.823387          3           100\n",
       "6     0.823375          2           100\n",
       "5     0.819671          2            50\n",
       "23    0.817794          6           500\n",
       "8     0.817428          3            10\n",
       "11    0.817420          3           500\n",
       "31    0.815181          8           500\n",
       "35    0.815181          9           500\n",
       "15    0.815169          4           500\n",
       "27    0.814057          7           500\n",
       "19    0.813670          5           500\n",
       "3     0.802459          1           500\n",
       "4     0.802081          2            10\n",
       "2     0.794603          1           100\n",
       "1     0.790487          1            50\n",
       "0     0.786750          1            10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic hyperparameter tuning\n",
    "models = []\n",
    "n_scores = []\n",
    "\n",
    "max_depth_values = range(1,10)\n",
    "n_estimators = [10, 50, 100, 500]\n",
    "\n",
    "for depth in max_depth_values:\n",
    "    for n in n_estimators:\n",
    "        xgb_model = XGBClassifier(max_depth=depth, n_estimators=n)\n",
    "        models.append(xgb_model)\n",
    "\n",
    "for model in models:\n",
    "    mean_score = np.mean(cross_val_score(model, X, y, scoring='accuracy', cv=rskf, n_jobs=-1))\n",
    "    n_scores.append({\n",
    "        \"mean_score\": mean_score,\n",
    "        \"max_depth\": model.max_depth,\n",
    "        \"n_estimators\": model.n_estimators\n",
    "        })\n",
    "    print(f\"Finished model: max_depth = {model.max_depth}, n_estimators = {model.n_estimators} --> mean_score = {mean_score:.3f}\")\n",
    "\n",
    "results_df = pd.DataFrame(n_scores, columns=n_scores[0].keys())   \n",
    "results_df.sort_values(\"mean_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished model: learning_rate = 0.4000, n_estimators = 50 --> mean_score = 0.828\n",
      "Finished model: learning_rate = 0.3000, n_estimators = 50 --> mean_score = 0.829\n",
      "Finished model: learning_rate = 0.2000, n_estimators = 50 --> mean_score = 0.829\n",
      "Finished model: learning_rate = 0.1000, n_estimators = 50 --> mean_score = 0.830\n",
      "Finished model: learning_rate = 0.4000, n_estimators = 75 --> mean_score = 0.828\n",
      "Finished model: learning_rate = 0.3000, n_estimators = 75 --> mean_score = 0.826\n",
      "Finished model: learning_rate = 0.2000, n_estimators = 75 --> mean_score = 0.831\n",
      "Finished model: learning_rate = 0.1000, n_estimators = 75 --> mean_score = 0.832\n",
      "Finished model: learning_rate = 0.4000, n_estimators = 100 --> mean_score = 0.825\n",
      "Finished model: learning_rate = 0.3000, n_estimators = 100 --> mean_score = 0.825\n",
      "Finished model: learning_rate = 0.2000, n_estimators = 100 --> mean_score = 0.829\n",
      "Finished model: learning_rate = 0.1000, n_estimators = 100 --> mean_score = 0.830\n",
      "Finished model: learning_rate = 0.4000, n_estimators = 125 --> mean_score = 0.823\n",
      "Finished model: learning_rate = 0.3000, n_estimators = 125 --> mean_score = 0.828\n",
      "Finished model: learning_rate = 0.2000, n_estimators = 125 --> mean_score = 0.827\n",
      "Finished model: learning_rate = 0.1000, n_estimators = 125 --> mean_score = 0.832\n",
      "Finished model: learning_rate = 0.4000, n_estimators = 150 --> mean_score = 0.821\n",
      "Finished model: learning_rate = 0.3000, n_estimators = 150 --> mean_score = 0.825\n",
      "Finished model: learning_rate = 0.2000, n_estimators = 150 --> mean_score = 0.824\n",
      "Finished model: learning_rate = 0.1000, n_estimators = 150 --> mean_score = 0.832\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.831989</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.831623</td>\n",
       "      <td>6</td>\n",
       "      <td>150</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.831623</td>\n",
       "      <td>6</td>\n",
       "      <td>75</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.830870</td>\n",
       "      <td>6</td>\n",
       "      <td>75</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.830141</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.830121</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.828631</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.828627</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.828618</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.827882</td>\n",
       "      <td>6</td>\n",
       "      <td>75</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.827873</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.827503</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.827129</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.826009</td>\n",
       "      <td>6</td>\n",
       "      <td>75</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.824894</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.824890</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.824890</td>\n",
       "      <td>6</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.823766</td>\n",
       "      <td>6</td>\n",
       "      <td>150</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.823025</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.821157</td>\n",
       "      <td>6</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_score  max_depth  n_estimators  learning_rate\n",
       "15    0.831989          6           125            0.1\n",
       "19    0.831623          6           150            0.1\n",
       "7     0.831623          6            75            0.1\n",
       "6     0.830870          6            75            0.2\n",
       "3     0.830141          6            50            0.1\n",
       "11    0.830121          6           100            0.1\n",
       "2     0.828631          6            50            0.2\n",
       "10    0.828627          6           100            0.2\n",
       "1     0.828618          6            50            0.3\n",
       "4     0.827882          6            75            0.4\n",
       "13    0.827873          6           125            0.3\n",
       "0     0.827503          6            50            0.4\n",
       "14    0.827129          6           125            0.2\n",
       "5     0.826009          6            75            0.3\n",
       "8     0.824894          6           100            0.4\n",
       "9     0.824890          6           100            0.3\n",
       "17    0.824890          6           150            0.3\n",
       "18    0.823766          6           150            0.2\n",
       "12    0.823025          6           125            0.4\n",
       "16    0.821157          6           150            0.4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic hyperparameter tuning\n",
    "models = []\n",
    "n_scores = []\n",
    "\n",
    "max_depth_values = [6]\n",
    "n_estimators = [50, 75, 100, 125, 150]\n",
    "learning_rates = [0.4, 0.3, 0.2, 0.1]\n",
    "\n",
    "for depth in max_depth_values:\n",
    "    for n in n_estimators:\n",
    "        for learning_rate in learning_rates:\n",
    "            xgb_model = XGBClassifier(max_depth=depth, n_estimators=n, learning_rate=learning_rate)\n",
    "            models.append(xgb_model)\n",
    "\n",
    "for model in models:\n",
    "    mean_score = np.mean(cross_val_score(model, X, y, scoring='accuracy', cv=rskf, n_jobs=-1))\n",
    "    n_scores.append({\n",
    "        \"mean_score\": mean_score,\n",
    "        \"max_depth\": model.max_depth,\n",
    "        \"n_estimators\": model.n_estimators,\n",
    "        \"learning_rate\": model.learning_rate\n",
    "        })\n",
    "    print(f\"Finished model: learning_rate = {model.learning_rate:.4f}, n_estimators = {model.n_estimators} --> mean_score = {mean_score:.3f}\")\n",
    "\n",
    "results_df = pd.DataFrame(n_scores, columns=n_scores[0].keys())\n",
    "results_df.sort_values(\"mean_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshc\\anaconda3\\envs\\pytorch\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\Users\\joshc\\anaconda3\\envs\\pytorch\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:09:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.834 (0.037)\n"
     ]
    }
   ],
   "source": [
    "final_model = XGBClassifier(max_depth=6, n_estimators=125, learning_rate=0.1)\n",
    "final_model.fit(X, y)\n",
    "n_scores = cross_val_score(final_model, X_scaled, y, scoring='accuracy', cv=rskf, n_jobs=-1)\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_df = pd.read_csv(final_test_csv_path)\n",
    "X_test = prep_data(test_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "y_pred_df = pd.DataFrame()\n",
    "y_pred_df[\"PassengerId\"] = test_data_df[\"PassengerId\"]\n",
    "y_pred_df[\"Survived\"] = y_pred\n",
    "\n",
    "y_pred_df.to_csv(\"Datasets/submission 10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f8db6a2d2432c89d112ec366f4d2e2376b3aa097399500d8f207a777f12d464"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
